{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed4da4d",
   "metadata": {},
   "source": [
    "## Tools\n",
    "https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05530b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "\n",
    "# Load the environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f77507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\"GOOGLE_API_KEY\" in os.environ and \"SERPAPI_API_KEY\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ba6556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_groq import ChatGroq\n",
    "chat_groq = ChatGroq(temperature=0, model='llama3-groq-8b-8192-tool-use-preview')\n",
    "llm = ChatGoogleGenerativeAI(temperature=0.9, model='gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850668f0",
   "metadata": {},
   "source": [
    "### Load predefined tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91caa10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in d:\\code\\python\\seti\\genai\\.venv\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in d:\\code\\python\\seti\\genai\\.venv\\lib\\site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\code\\python\\seti\\genai\\.venv\\lib\\site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\code\\python\\seti\\genai\\.venv\\lib\\site-packages (from requests->google-search-results) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\code\\python\\seti\\genai\\.venv\\lib\\site-packages (from requests->google-search-results) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\code\\python\\seti\\genai\\.venv\\lib\\site-packages (from requests->google-search-results) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rpcio (D:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rpcio (D:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~rpcio (D:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d22c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "from langchain.agents import load_tools\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320cf8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Search' description='A search engine. Useful for when you need to answer questions about current events. Input should be a search query.' func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='0e06fba99dfce09b1ef7b14736248a801e4b6da97d58aeea528843c5b8ccb5d1', aiosession=None)> coroutine=<bound method SerpAPIWrapper.arun of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='0e06fba99dfce09b1ef7b14736248a801e4b6da97d58aeea528843c5b8ccb5d1', aiosession=None)>\n",
      "name='Calculator' description='Useful for when you need to answer questions about math.' func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatGoogleGenerativeAI(model='models/gemini-pro', temperature=0.9, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000228959DBC20>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x0000022895A301D0>, default_metadata=())))> coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatGoogleGenerativeAI(model='models/gemini-pro', temperature=0.9, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000228959DBC20>, async_client=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsyncClient object at 0x0000022895A301D0>, default_metadata=())))>\n"
     ]
    }
   ],
   "source": [
    "for tool in tools:\n",
    "    print(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0520c4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'block_position': 'top',\n",
      "  'extensions': ['Free cancellation'],\n",
      "  'extracted_price': 30,\n",
      "  'link': 'https://www.getyourguide.com/',\n",
      "  'position': 1,\n",
      "  'price': '$30',\n",
      "  'rating': 4.8,\n",
      "  'reviews': 1400,\n",
      "  'reviews_original': '1.4K',\n",
      "  'source': 'GetYourGuide',\n",
      "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTasqbabBkYIdajSgMxxnjrtVBLoZcRgmVsfM9h7H-RbBXb&s=4',\n",
      "  'title': 'Medellin: Guatapé Tour, Lunch, Cruise, & Piedra del Peñol'},\n",
      " {'block_position': 'top',\n",
      "  'extensions': ['Free cancellation'],\n",
      "  'extracted_price': 63,\n",
      "  'link': 'https://www.getyourguide.com/',\n",
      "  'position': 2,\n",
      "  'price': '$63',\n",
      "  'rating': 4.8,\n",
      "  'reviews': 102,\n",
      "  'reviews_original': '102',\n",
      "  'source': 'GetYourGuide',\n",
      "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTyIocXnXTZaKaQJzYbMWNZnGAThDHAN4Zcwh1Z_X66hE0u&s=4',\n",
      "  'title': 'Medellin: Coffee Tour and Wellness Spa'},\n",
      " {'block_position': 'top',\n",
      "  'extensions': ['Free cancellation'],\n",
      "  'extracted_price': 55,\n",
      "  'link': 'https://www.getyourguide.com/',\n",
      "  'position': 3,\n",
      "  'price': '$55',\n",
      "  'rating': 4.8,\n",
      "  'reviews': 888,\n",
      "  'reviews_original': '888',\n",
      "  'source': 'GetYourGuide',\n",
      "  'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQgnWdcMR18Uc2JaShoqVyqSALR5NLfL8DL1-XGdzu3IHko&s=4',\n",
      "  'title': 'Medellín: Coffee Tour With Tastings and Lunch'}]\n"
     ]
    }
   ],
   "source": [
    "tools[0].invoke(\"Que hay para hacer en medellín? 3 sitios\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c027e4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown format from LLM: This is not a math problem, so I cannot translate it into a mathematical expression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtools\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQue hay para hacer en medellín? 3 sitios\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:397\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, Dict, ToolCall],\n\u001b[0;32m    393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    396\u001b[0m     tool_input, kwargs \u001b[38;5;241m=\u001b[39m _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:586\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    585\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    587\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    588\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:555\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    554\u001b[0m     tool_kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 555\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\tools\\simple.py:84\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m     83\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     emit_warning()\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:598\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    599\u001b[0m         _output_key\n\u001b[0;32m    600\u001b[0m     ]\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    604\u001b[0m         _output_key\n\u001b[0;32m    605\u001b[0m     ]\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    179\u001b[0m     emit_warning()\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:381\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    379\u001b[0m }\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:164\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    163\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    165\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:154\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 154\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    157\u001b[0m     )\n\u001b[0;32m    159\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    160\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:274\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    268\u001b[0m _run_manager\u001b[38;5;241m.\u001b[39mon_text(inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key])\n\u001b[0;32m    269\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    270\u001b[0m     question\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key],\n\u001b[0;32m    271\u001b[0m     stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```output\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    272\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(),\n\u001b[0;32m    273\u001b[0m )\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_llm_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_run_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:237\u001b[0m, in \u001b[0;36mLLMMathChain._process_llm_result\u001b[1;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[0;32m    235\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m llm_output\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown format from LLM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer}\n",
      "\u001b[1;31mValueError\u001b[0m: unknown format from LLM: This is not a math problem, so I cannot translate it into a mathematical expression."
     ]
    }
   ],
   "source": [
    "tools[1].invoke(\"Que hay para hacer en medellín? 3 sitios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd132a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Search', 'arguments': '{\"__arg1\": \"Who is the current president of Japan?\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-f74ad4d1-853a-44f3-8f2f-6e69c5faa7b7-0', tool_calls=[{'name': 'Search', 'args': {'__arg1': 'Who is the current president of Japan?'}, 'id': '89057795-7169-40de-819c-eddc451b4a13', 'type': 'tool_call'}], usage_metadata={'input_tokens': 111, 'output_tokens': 21, 'total_tokens': 132})\n",
      "Contenido:\n",
      "\n",
      "Tool Calls:\n",
      "[{'name': 'Search', 'args': {'__arg1': 'Who is the current president of Japan?'}, 'id': '89057795-7169-40de-819c-eddc451b4a13', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "response1 = llm_with_tools.invoke(\"Quién es el actual presidente de Japón?\")\n",
    "print(response1)\n",
    "print(\"Contenido:\")\n",
    "print(response1.content) #Vacío\n",
    "print(\"Tool Calls:\")\n",
    "print(response1.tool_calls) # La invocación que requiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b53e04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido:\n",
      "I cannot fulfill this request. I do not understand Spanish.\n",
      "Tool calls:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "response2 = llm_with_tools.invoke(\"hola\")\n",
    "print(\"Contenido:\")\n",
    "print(response2.content) #Respuesta\n",
    "print(\"Tool calls:\")\n",
    "print(response2.tool_calls) # vacio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4efd22",
   "metadata": {},
   "source": [
    "### Create an Agent - Traditional method (initialize_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20f48e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\python\\SETI\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "from langchain.agents import initialize_agent #Forma tradicional\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215c67d",
   "metadata": {},
   "source": [
    "## ReAct = Reasoning + Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89728919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search about the president of Bolivia and calculate the largest even number smaller than his age.\n",
      "Action: Search\n",
      "Action Input: presidente de Bolivia\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLuis Arce Catacora\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe president of Bolivia is Luis Arce Catacora. Let us calculate the largest even number smaller than his age.\n",
      "Action: Search\n",
      "Action Input: Luis Arce Catacora edad\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m60 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe president of Bolivia is 60 years old, so the largest even number smaller than his age is 58.\n",
      "Final Answer: 58\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'58'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Quién es el presidente de Bolivia? y cual es el mayor número par menor a su edad?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0f4e5",
   "metadata": {},
   "source": [
    "### Create an Agent - LangGraph Prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3934501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b907d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='hi!' id='c1272e8c-10db-4421-b061-4691543eb828'\n",
      "content='Hello there! I am a text-based AI assistant. How can I help you today?' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-db1527fe-ca4b-4b1a-b2e6-cad594ddfcda-0' usage_metadata={'input_tokens': 105, 'output_tokens': 19, 'total_tokens': 124}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "for msg in response[\"messages\"]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "831b5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"Quién es el presidente de Bolivia? y cuál es el mayor número par menor a su edad?\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c5d75ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Quíen es el presidente de Bolivia? y cual es el mayor número par menor a su edad?' id='66225332-c98a-4d3b-966a-7ee6dbb07e7e'\n",
      "content='' additional_kwargs={'function_call': {'name': 'Search', 'arguments': '{\"__arg1\": \"presidente de Bolivia\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-607a8520-bec9-4461-9183-12dcd23a4d24-0' tool_calls=[{'name': 'Search', 'args': {'__arg1': 'presidente de Bolivia'}, 'id': '7fd76503-ae15-4690-916b-bb75cb8dbcbf', 'type': 'tool_call'}] usage_metadata={'input_tokens': 124, 'output_tokens': 16, 'total_tokens': 140}\n",
      "content='Luis Arce Catacora' name='Search' id='75787972-52a5-4682-b589-ebc4b193b680' tool_call_id='7fd76503-ae15-4690-916b-bb75cb8dbcbf'\n",
      "content='' additional_kwargs={'function_call': {'name': 'Calculator', 'arguments': '{\"__arg1\": \"mayor n\\\\u00famero par menor a 72\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-38384a3a-56c2-4c80-8d43-b0c9be2686ca-0' tool_calls=[{'name': 'Calculator', 'args': {'__arg1': 'mayor número par menor a 72'}, 'id': '10e90941-d2c2-4cbe-bf8b-3ebbe86afe21', 'type': 'tool_call'}] usage_metadata={'input_tokens': 159, 'output_tokens': 21, 'total_tokens': 180}\n",
      "content='Answer: 36' name='Calculator' id='4266371a-e89b-4f0b-b220-f1742cd726b5' tool_call_id='10e90941-d2c2-4cbe-bf8b-3ebbe86afe21'\n",
      "content='El presidente de Bolivia es Luis Arce Catacora y el mayor número par menor a su edad es 70.' response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]} id='run-54407c12-c862-4612-87c3-354a847d7b9b-0' usage_metadata={'input_tokens': 199, 'output_tokens': 24, 'total_tokens': 223}\n"
     ]
    }
   ],
   "source": [
    "for msg in response[\"messages\"]:\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
